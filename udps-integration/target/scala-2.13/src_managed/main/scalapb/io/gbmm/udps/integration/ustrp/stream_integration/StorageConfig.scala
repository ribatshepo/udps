// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!
//
// Protofile syntax: PROTO3

package io.gbmm.udps.integration.ustrp.stream_integration

/** Full storage configuration for a stream-to-storage pipeline.
  *
  * @param configId
  *   Unique configuration identifier.
  * @param pipelineId
  *   Pipeline identifier this configuration belongs to.
  * @param tenantId
  *   Tenant that owns this configuration.
  * @param targetDatabase
  *   Target database in the UDPS catalog.
  * @param targetSchema
  *   Target schema in the UDPS catalog.
  * @param targetTable
  *   Target table name in the UDPS catalog.
  * @param format
  *   Storage format for persisted data.
  * @param compression
  *   Compression algorithm.
  * @param partitioning
  *   Partitioning configuration.
  * @param compaction
  *   Compaction configuration.
  * @param retention
  *   Retention policy.
  * @param tier
  *   Current storage tier.
  * @param flushIntervalSeconds
  *   Flush interval -- how often buffered stream data is written to storage.
  * @param maxBufferBytes
  *   Maximum buffer size in bytes before a forced flush.
  * @param maxBufferRecords
  *   Maximum number of records to buffer before a forced flush.
  * @param schemaId
  *   Schema identifier from StreamSchemaService for the target table.
  * @param properties
  *   Additional storage-specific properties.
  * @param createdAt
  *   When this configuration was created.
  * @param updatedAt
  *   When this configuration was last updated.
  */
@SerialVersionUID(0L)
final case class StorageConfig(
    configId: _root_.scala.Predef.String = "",
    pipelineId: _root_.scala.Predef.String = "",
    tenantId: _root_.scala.Predef.String = "",
    targetDatabase: _root_.scala.Predef.String = "",
    targetSchema: _root_.scala.Predef.String = "",
    targetTable: _root_.scala.Predef.String = "",
    format: io.gbmm.udps.integration.ustrp.stream_integration.StorageFormat = io.gbmm.udps.integration.ustrp.stream_integration.StorageFormat.STORAGE_FORMAT_UNSPECIFIED,
    compression: io.gbmm.udps.integration.ustrp.stream_integration.CompressionCodec = io.gbmm.udps.integration.ustrp.stream_integration.CompressionCodec.COMPRESSION_CODEC_UNSPECIFIED,
    partitioning: _root_.scala.Option[io.gbmm.udps.integration.ustrp.stream_integration.PartitionConfig] = _root_.scala.None,
    compaction: _root_.scala.Option[io.gbmm.udps.integration.ustrp.stream_integration.CompactionConfig] = _root_.scala.None,
    retention: _root_.scala.Option[io.gbmm.udps.integration.ustrp.stream_integration.RetentionPolicy] = _root_.scala.None,
    tier: io.gbmm.udps.integration.ustrp.stream_integration.StorageTier = io.gbmm.udps.integration.ustrp.stream_integration.StorageTier.STORAGE_TIER_UNSPECIFIED,
    flushIntervalSeconds: _root_.scala.Long = 0L,
    maxBufferBytes: _root_.scala.Long = 0L,
    maxBufferRecords: _root_.scala.Long = 0L,
    schemaId: _root_.scala.Predef.String = "",
    properties: _root_.scala.collection.immutable.Map[_root_.scala.Predef.String, _root_.scala.Predef.String] = _root_.scala.collection.immutable.Map.empty,
    createdAt: _root_.scala.Option[com.google.protobuf.timestamp.Timestamp] = _root_.scala.None,
    updatedAt: _root_.scala.Option[com.google.protobuf.timestamp.Timestamp] = _root_.scala.None,
    unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
    ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[StorageConfig] {
    @transient
    private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
    private[this] def __computeSerializedSize(): _root_.scala.Int = {
      var __size = 0
      
      {
        val __value = configId
        if (!__value.isEmpty) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(1, __value)
        }
      };
      
      {
        val __value = pipelineId
        if (!__value.isEmpty) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(2, __value)
        }
      };
      
      {
        val __value = tenantId
        if (!__value.isEmpty) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(3, __value)
        }
      };
      
      {
        val __value = targetDatabase
        if (!__value.isEmpty) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(4, __value)
        }
      };
      
      {
        val __value = targetSchema
        if (!__value.isEmpty) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(5, __value)
        }
      };
      
      {
        val __value = targetTable
        if (!__value.isEmpty) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(6, __value)
        }
      };
      
      {
        val __value = format.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(7, __value)
        }
      };
      
      {
        val __value = compression.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(8, __value)
        }
      };
      if (partitioning.isDefined) {
        val __value = partitioning.get
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      if (compaction.isDefined) {
        val __value = compaction.get
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      if (retention.isDefined) {
        val __value = retention.get
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      
      {
        val __value = tier.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(12, __value)
        }
      };
      
      {
        val __value = flushIntervalSeconds
        if (__value != 0L) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(13, __value)
        }
      };
      
      {
        val __value = maxBufferBytes
        if (__value != 0L) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(14, __value)
        }
      };
      
      {
        val __value = maxBufferRecords
        if (__value != 0L) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(15, __value)
        }
      };
      
      {
        val __value = schemaId
        if (!__value.isEmpty) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(16, __value)
        }
      };
      properties.foreach { __item =>
        val __value = io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig._typemapper_properties.toBase(__item)
        __size += 2 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      }
      if (createdAt.isDefined) {
        val __value = createdAt.get
        __size += 2 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      if (updatedAt.isDefined) {
        val __value = updatedAt.get
        __size += 2 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      __size += unknownFields.serializedSize
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var __size = __serializedSizeMemoized
      if (__size == 0) {
        __size = __computeSerializedSize() + 1
        __serializedSizeMemoized = __size
      }
      __size - 1
      
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      {
        val __v = configId
        if (!__v.isEmpty) {
          _output__.writeString(1, __v)
        }
      };
      {
        val __v = pipelineId
        if (!__v.isEmpty) {
          _output__.writeString(2, __v)
        }
      };
      {
        val __v = tenantId
        if (!__v.isEmpty) {
          _output__.writeString(3, __v)
        }
      };
      {
        val __v = targetDatabase
        if (!__v.isEmpty) {
          _output__.writeString(4, __v)
        }
      };
      {
        val __v = targetSchema
        if (!__v.isEmpty) {
          _output__.writeString(5, __v)
        }
      };
      {
        val __v = targetTable
        if (!__v.isEmpty) {
          _output__.writeString(6, __v)
        }
      };
      {
        val __v = format.value
        if (__v != 0) {
          _output__.writeEnum(7, __v)
        }
      };
      {
        val __v = compression.value
        if (__v != 0) {
          _output__.writeEnum(8, __v)
        }
      };
      partitioning.foreach { __v =>
        val __m = __v
        _output__.writeTag(9, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      compaction.foreach { __v =>
        val __m = __v
        _output__.writeTag(10, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      retention.foreach { __v =>
        val __m = __v
        _output__.writeTag(11, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      {
        val __v = tier.value
        if (__v != 0) {
          _output__.writeEnum(12, __v)
        }
      };
      {
        val __v = flushIntervalSeconds
        if (__v != 0L) {
          _output__.writeInt64(13, __v)
        }
      };
      {
        val __v = maxBufferBytes
        if (__v != 0L) {
          _output__.writeInt64(14, __v)
        }
      };
      {
        val __v = maxBufferRecords
        if (__v != 0L) {
          _output__.writeInt64(15, __v)
        }
      };
      {
        val __v = schemaId
        if (!__v.isEmpty) {
          _output__.writeString(16, __v)
        }
      };
      properties.foreach { __v =>
        val __m = io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig._typemapper_properties.toBase(__v)
        _output__.writeTag(17, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      createdAt.foreach { __v =>
        val __m = __v
        _output__.writeTag(18, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      updatedAt.foreach { __v =>
        val __m = __v
        _output__.writeTag(19, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      unknownFields.writeTo(_output__)
    }
    def withConfigId(__v: _root_.scala.Predef.String): StorageConfig = copy(configId = __v)
    def withPipelineId(__v: _root_.scala.Predef.String): StorageConfig = copy(pipelineId = __v)
    def withTenantId(__v: _root_.scala.Predef.String): StorageConfig = copy(tenantId = __v)
    def withTargetDatabase(__v: _root_.scala.Predef.String): StorageConfig = copy(targetDatabase = __v)
    def withTargetSchema(__v: _root_.scala.Predef.String): StorageConfig = copy(targetSchema = __v)
    def withTargetTable(__v: _root_.scala.Predef.String): StorageConfig = copy(targetTable = __v)
    def withFormat(__v: io.gbmm.udps.integration.ustrp.stream_integration.StorageFormat): StorageConfig = copy(format = __v)
    def withCompression(__v: io.gbmm.udps.integration.ustrp.stream_integration.CompressionCodec): StorageConfig = copy(compression = __v)
    def getPartitioning: io.gbmm.udps.integration.ustrp.stream_integration.PartitionConfig = partitioning.getOrElse(io.gbmm.udps.integration.ustrp.stream_integration.PartitionConfig.defaultInstance)
    def clearPartitioning: StorageConfig = copy(partitioning = _root_.scala.None)
    def withPartitioning(__v: io.gbmm.udps.integration.ustrp.stream_integration.PartitionConfig): StorageConfig = copy(partitioning = Option(__v))
    def getCompaction: io.gbmm.udps.integration.ustrp.stream_integration.CompactionConfig = compaction.getOrElse(io.gbmm.udps.integration.ustrp.stream_integration.CompactionConfig.defaultInstance)
    def clearCompaction: StorageConfig = copy(compaction = _root_.scala.None)
    def withCompaction(__v: io.gbmm.udps.integration.ustrp.stream_integration.CompactionConfig): StorageConfig = copy(compaction = Option(__v))
    def getRetention: io.gbmm.udps.integration.ustrp.stream_integration.RetentionPolicy = retention.getOrElse(io.gbmm.udps.integration.ustrp.stream_integration.RetentionPolicy.defaultInstance)
    def clearRetention: StorageConfig = copy(retention = _root_.scala.None)
    def withRetention(__v: io.gbmm.udps.integration.ustrp.stream_integration.RetentionPolicy): StorageConfig = copy(retention = Option(__v))
    def withTier(__v: io.gbmm.udps.integration.ustrp.stream_integration.StorageTier): StorageConfig = copy(tier = __v)
    def withFlushIntervalSeconds(__v: _root_.scala.Long): StorageConfig = copy(flushIntervalSeconds = __v)
    def withMaxBufferBytes(__v: _root_.scala.Long): StorageConfig = copy(maxBufferBytes = __v)
    def withMaxBufferRecords(__v: _root_.scala.Long): StorageConfig = copy(maxBufferRecords = __v)
    def withSchemaId(__v: _root_.scala.Predef.String): StorageConfig = copy(schemaId = __v)
    def clearProperties = copy(properties = _root_.scala.collection.immutable.Map.empty)
    def addProperties(__vs: (_root_.scala.Predef.String, _root_.scala.Predef.String) *): StorageConfig = addAllProperties(__vs)
    def addAllProperties(__vs: Iterable[(_root_.scala.Predef.String, _root_.scala.Predef.String)]): StorageConfig = copy(properties = properties ++ __vs)
    def withProperties(__v: _root_.scala.collection.immutable.Map[_root_.scala.Predef.String, _root_.scala.Predef.String]): StorageConfig = copy(properties = __v)
    def getCreatedAt: com.google.protobuf.timestamp.Timestamp = createdAt.getOrElse(com.google.protobuf.timestamp.Timestamp.defaultInstance)
    def clearCreatedAt: StorageConfig = copy(createdAt = _root_.scala.None)
    def withCreatedAt(__v: com.google.protobuf.timestamp.Timestamp): StorageConfig = copy(createdAt = Option(__v))
    def getUpdatedAt: com.google.protobuf.timestamp.Timestamp = updatedAt.getOrElse(com.google.protobuf.timestamp.Timestamp.defaultInstance)
    def clearUpdatedAt: StorageConfig = copy(updatedAt = _root_.scala.None)
    def withUpdatedAt(__v: com.google.protobuf.timestamp.Timestamp): StorageConfig = copy(updatedAt = Option(__v))
    def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
    def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => {
          val __t = configId
          if (__t != "") __t else null
        }
        case 2 => {
          val __t = pipelineId
          if (__t != "") __t else null
        }
        case 3 => {
          val __t = tenantId
          if (__t != "") __t else null
        }
        case 4 => {
          val __t = targetDatabase
          if (__t != "") __t else null
        }
        case 5 => {
          val __t = targetSchema
          if (__t != "") __t else null
        }
        case 6 => {
          val __t = targetTable
          if (__t != "") __t else null
        }
        case 7 => {
          val __t = format.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 8 => {
          val __t = compression.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 9 => partitioning.orNull
        case 10 => compaction.orNull
        case 11 => retention.orNull
        case 12 => {
          val __t = tier.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 13 => {
          val __t = flushIntervalSeconds
          if (__t != 0L) __t else null
        }
        case 14 => {
          val __t = maxBufferBytes
          if (__t != 0L) __t else null
        }
        case 15 => {
          val __t = maxBufferRecords
          if (__t != 0L) __t else null
        }
        case 16 => {
          val __t = schemaId
          if (__t != "") __t else null
        }
        case 17 => properties.iterator.map(io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig._typemapper_properties.toBase(_)).toSeq
        case 18 => createdAt.orNull
        case 19 => updatedAt.orNull
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PString(configId)
        case 2 => _root_.scalapb.descriptors.PString(pipelineId)
        case 3 => _root_.scalapb.descriptors.PString(tenantId)
        case 4 => _root_.scalapb.descriptors.PString(targetDatabase)
        case 5 => _root_.scalapb.descriptors.PString(targetSchema)
        case 6 => _root_.scalapb.descriptors.PString(targetTable)
        case 7 => _root_.scalapb.descriptors.PEnum(format.scalaValueDescriptor)
        case 8 => _root_.scalapb.descriptors.PEnum(compression.scalaValueDescriptor)
        case 9 => partitioning.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 10 => compaction.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 11 => retention.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 12 => _root_.scalapb.descriptors.PEnum(tier.scalaValueDescriptor)
        case 13 => _root_.scalapb.descriptors.PLong(flushIntervalSeconds)
        case 14 => _root_.scalapb.descriptors.PLong(maxBufferBytes)
        case 15 => _root_.scalapb.descriptors.PLong(maxBufferRecords)
        case 16 => _root_.scalapb.descriptors.PString(schemaId)
        case 17 => _root_.scalapb.descriptors.PRepeated(properties.iterator.map(io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig._typemapper_properties.toBase(_).toPMessage).toVector)
        case 18 => createdAt.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 19 => updatedAt.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
    def companion: io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig.type = io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig
    // @@protoc_insertion_point(GeneratedMessage[ustrp.integration.StorageConfig])
}

object StorageConfig extends scalapb.GeneratedMessageCompanion[io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig = {
    var __configId: _root_.scala.Predef.String = ""
    var __pipelineId: _root_.scala.Predef.String = ""
    var __tenantId: _root_.scala.Predef.String = ""
    var __targetDatabase: _root_.scala.Predef.String = ""
    var __targetSchema: _root_.scala.Predef.String = ""
    var __targetTable: _root_.scala.Predef.String = ""
    var __format: io.gbmm.udps.integration.ustrp.stream_integration.StorageFormat = io.gbmm.udps.integration.ustrp.stream_integration.StorageFormat.STORAGE_FORMAT_UNSPECIFIED
    var __compression: io.gbmm.udps.integration.ustrp.stream_integration.CompressionCodec = io.gbmm.udps.integration.ustrp.stream_integration.CompressionCodec.COMPRESSION_CODEC_UNSPECIFIED
    var __partitioning: _root_.scala.Option[io.gbmm.udps.integration.ustrp.stream_integration.PartitionConfig] = _root_.scala.None
    var __compaction: _root_.scala.Option[io.gbmm.udps.integration.ustrp.stream_integration.CompactionConfig] = _root_.scala.None
    var __retention: _root_.scala.Option[io.gbmm.udps.integration.ustrp.stream_integration.RetentionPolicy] = _root_.scala.None
    var __tier: io.gbmm.udps.integration.ustrp.stream_integration.StorageTier = io.gbmm.udps.integration.ustrp.stream_integration.StorageTier.STORAGE_TIER_UNSPECIFIED
    var __flushIntervalSeconds: _root_.scala.Long = 0L
    var __maxBufferBytes: _root_.scala.Long = 0L
    var __maxBufferRecords: _root_.scala.Long = 0L
    var __schemaId: _root_.scala.Predef.String = ""
    val __properties: _root_.scala.collection.mutable.Builder[(_root_.scala.Predef.String, _root_.scala.Predef.String), _root_.scala.collection.immutable.Map[_root_.scala.Predef.String, _root_.scala.Predef.String]] = _root_.scala.collection.immutable.Map.newBuilder[_root_.scala.Predef.String, _root_.scala.Predef.String]
    var __createdAt: _root_.scala.Option[com.google.protobuf.timestamp.Timestamp] = _root_.scala.None
    var __updatedAt: _root_.scala.Option[com.google.protobuf.timestamp.Timestamp] = _root_.scala.None
    var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 10 =>
          __configId = _input__.readStringRequireUtf8()
        case 18 =>
          __pipelineId = _input__.readStringRequireUtf8()
        case 26 =>
          __tenantId = _input__.readStringRequireUtf8()
        case 34 =>
          __targetDatabase = _input__.readStringRequireUtf8()
        case 42 =>
          __targetSchema = _input__.readStringRequireUtf8()
        case 50 =>
          __targetTable = _input__.readStringRequireUtf8()
        case 56 =>
          __format = io.gbmm.udps.integration.ustrp.stream_integration.StorageFormat.fromValue(_input__.readEnum())
        case 64 =>
          __compression = io.gbmm.udps.integration.ustrp.stream_integration.CompressionCodec.fromValue(_input__.readEnum())
        case 74 =>
          __partitioning = _root_.scala.Option(__partitioning.fold(_root_.scalapb.LiteParser.readMessage[io.gbmm.udps.integration.ustrp.stream_integration.PartitionConfig](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
        case 82 =>
          __compaction = _root_.scala.Option(__compaction.fold(_root_.scalapb.LiteParser.readMessage[io.gbmm.udps.integration.ustrp.stream_integration.CompactionConfig](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
        case 90 =>
          __retention = _root_.scala.Option(__retention.fold(_root_.scalapb.LiteParser.readMessage[io.gbmm.udps.integration.ustrp.stream_integration.RetentionPolicy](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
        case 96 =>
          __tier = io.gbmm.udps.integration.ustrp.stream_integration.StorageTier.fromValue(_input__.readEnum())
        case 104 =>
          __flushIntervalSeconds = _input__.readInt64()
        case 112 =>
          __maxBufferBytes = _input__.readInt64()
        case 120 =>
          __maxBufferRecords = _input__.readInt64()
        case 130 =>
          __schemaId = _input__.readStringRequireUtf8()
        case 138 =>
          __properties += io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig._typemapper_properties.toCustom(_root_.scalapb.LiteParser.readMessage[io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig.PropertiesEntry](_input__))
        case 146 =>
          __createdAt = _root_.scala.Option(__createdAt.fold(_root_.scalapb.LiteParser.readMessage[com.google.protobuf.timestamp.Timestamp](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
        case 154 =>
          __updatedAt = _root_.scala.Option(__updatedAt.fold(_root_.scalapb.LiteParser.readMessage[com.google.protobuf.timestamp.Timestamp](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
        case tag =>
          if (_unknownFields__ == null) {
            _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
          }
          _unknownFields__.parseField(tag, _input__)
      }
    }
    io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig(
        configId = __configId,
        pipelineId = __pipelineId,
        tenantId = __tenantId,
        targetDatabase = __targetDatabase,
        targetSchema = __targetSchema,
        targetTable = __targetTable,
        format = __format,
        compression = __compression,
        partitioning = __partitioning,
        compaction = __compaction,
        retention = __retention,
        tier = __tier,
        flushIntervalSeconds = __flushIntervalSeconds,
        maxBufferBytes = __maxBufferBytes,
        maxBufferRecords = __maxBufferRecords,
        schemaId = __schemaId,
        properties = __properties.result(),
        createdAt = __createdAt,
        updatedAt = __updatedAt,
        unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig(
        configId = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
        pipelineId = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
        tenantId = __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
        targetDatabase = __fieldsMap.get(scalaDescriptor.findFieldByNumber(4).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
        targetSchema = __fieldsMap.get(scalaDescriptor.findFieldByNumber(5).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
        targetTable = __fieldsMap.get(scalaDescriptor.findFieldByNumber(6).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
        format = io.gbmm.udps.integration.ustrp.stream_integration.StorageFormat.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(7).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(io.gbmm.udps.integration.ustrp.stream_integration.StorageFormat.STORAGE_FORMAT_UNSPECIFIED.scalaValueDescriptor).number),
        compression = io.gbmm.udps.integration.ustrp.stream_integration.CompressionCodec.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(8).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(io.gbmm.udps.integration.ustrp.stream_integration.CompressionCodec.COMPRESSION_CODEC_UNSPECIFIED.scalaValueDescriptor).number),
        partitioning = __fieldsMap.get(scalaDescriptor.findFieldByNumber(9).get).flatMap(_.as[_root_.scala.Option[io.gbmm.udps.integration.ustrp.stream_integration.PartitionConfig]]),
        compaction = __fieldsMap.get(scalaDescriptor.findFieldByNumber(10).get).flatMap(_.as[_root_.scala.Option[io.gbmm.udps.integration.ustrp.stream_integration.CompactionConfig]]),
        retention = __fieldsMap.get(scalaDescriptor.findFieldByNumber(11).get).flatMap(_.as[_root_.scala.Option[io.gbmm.udps.integration.ustrp.stream_integration.RetentionPolicy]]),
        tier = io.gbmm.udps.integration.ustrp.stream_integration.StorageTier.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(12).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(io.gbmm.udps.integration.ustrp.stream_integration.StorageTier.STORAGE_TIER_UNSPECIFIED.scalaValueDescriptor).number),
        flushIntervalSeconds = __fieldsMap.get(scalaDescriptor.findFieldByNumber(13).get).map(_.as[_root_.scala.Long]).getOrElse(0L),
        maxBufferBytes = __fieldsMap.get(scalaDescriptor.findFieldByNumber(14).get).map(_.as[_root_.scala.Long]).getOrElse(0L),
        maxBufferRecords = __fieldsMap.get(scalaDescriptor.findFieldByNumber(15).get).map(_.as[_root_.scala.Long]).getOrElse(0L),
        schemaId = __fieldsMap.get(scalaDescriptor.findFieldByNumber(16).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
        properties = __fieldsMap.get(scalaDescriptor.findFieldByNumber(17).get).map(_.as[_root_.scala.Seq[io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig.PropertiesEntry]]).getOrElse(_root_.scala.Seq.empty).iterator.map(io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig._typemapper_properties.toCustom(_)).toMap,
        createdAt = __fieldsMap.get(scalaDescriptor.findFieldByNumber(18).get).flatMap(_.as[_root_.scala.Option[com.google.protobuf.timestamp.Timestamp]]),
        updatedAt = __fieldsMap.get(scalaDescriptor.findFieldByNumber(19).get).flatMap(_.as[_root_.scala.Option[com.google.protobuf.timestamp.Timestamp]])
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = StreamIntegrationProto.javaDescriptor.getMessageTypes().get(17)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = StreamIntegrationProto.scalaDescriptor.messages(17)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
    var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
    (__number: @_root_.scala.unchecked) match {
      case 9 => __out = io.gbmm.udps.integration.ustrp.stream_integration.PartitionConfig
      case 10 => __out = io.gbmm.udps.integration.ustrp.stream_integration.CompactionConfig
      case 11 => __out = io.gbmm.udps.integration.ustrp.stream_integration.RetentionPolicy
      case 17 => __out = io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig.PropertiesEntry
      case 18 => __out = com.google.protobuf.timestamp.Timestamp
      case 19 => __out = com.google.protobuf.timestamp.Timestamp
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] =
    Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]](
      _root_.io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig.PropertiesEntry
    )
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = {
    (__fieldNumber: @_root_.scala.unchecked) match {
      case 7 => io.gbmm.udps.integration.ustrp.stream_integration.StorageFormat
      case 8 => io.gbmm.udps.integration.ustrp.stream_integration.CompressionCodec
      case 12 => io.gbmm.udps.integration.ustrp.stream_integration.StorageTier
    }
  }
  lazy val defaultInstance = io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig(
    configId = "",
    pipelineId = "",
    tenantId = "",
    targetDatabase = "",
    targetSchema = "",
    targetTable = "",
    format = io.gbmm.udps.integration.ustrp.stream_integration.StorageFormat.STORAGE_FORMAT_UNSPECIFIED,
    compression = io.gbmm.udps.integration.ustrp.stream_integration.CompressionCodec.COMPRESSION_CODEC_UNSPECIFIED,
    partitioning = _root_.scala.None,
    compaction = _root_.scala.None,
    retention = _root_.scala.None,
    tier = io.gbmm.udps.integration.ustrp.stream_integration.StorageTier.STORAGE_TIER_UNSPECIFIED,
    flushIntervalSeconds = 0L,
    maxBufferBytes = 0L,
    maxBufferRecords = 0L,
    schemaId = "",
    properties = _root_.scala.collection.immutable.Map.empty,
    createdAt = _root_.scala.None,
    updatedAt = _root_.scala.None
  )
  @SerialVersionUID(0L)
  final case class PropertiesEntry(
      key: _root_.scala.Predef.String = "",
      value: _root_.scala.Predef.String = "",
      unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
      ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[PropertiesEntry] {
      @transient
      private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
      private[this] def __computeSerializedSize(): _root_.scala.Int = {
        var __size = 0
        
        {
          val __value = key
          if (!__value.isEmpty) {
            __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(1, __value)
          }
        };
        
        {
          val __value = value
          if (!__value.isEmpty) {
            __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(2, __value)
          }
        };
        __size += unknownFields.serializedSize
        __size
      }
      override def serializedSize: _root_.scala.Int = {
        var __size = __serializedSizeMemoized
        if (__size == 0) {
          __size = __computeSerializedSize() + 1
          __serializedSizeMemoized = __size
        }
        __size - 1
        
      }
      def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
        {
          val __v = key
          if (!__v.isEmpty) {
            _output__.writeString(1, __v)
          }
        };
        {
          val __v = value
          if (!__v.isEmpty) {
            _output__.writeString(2, __v)
          }
        };
        unknownFields.writeTo(_output__)
      }
      def withKey(__v: _root_.scala.Predef.String): PropertiesEntry = copy(key = __v)
      def withValue(__v: _root_.scala.Predef.String): PropertiesEntry = copy(value = __v)
      def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
      def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
      def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
        (__fieldNumber: @_root_.scala.unchecked) match {
          case 1 => {
            val __t = key
            if (__t != "") __t else null
          }
          case 2 => {
            val __t = value
            if (__t != "") __t else null
          }
        }
      }
      def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
        _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
        (__field.number: @_root_.scala.unchecked) match {
          case 1 => _root_.scalapb.descriptors.PString(key)
          case 2 => _root_.scalapb.descriptors.PString(value)
        }
      }
      def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
      def companion: io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig.PropertiesEntry.type = io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig.PropertiesEntry
      // @@protoc_insertion_point(GeneratedMessage[ustrp.integration.StorageConfig.PropertiesEntry])
  }
  
  object PropertiesEntry extends scalapb.GeneratedMessageCompanion[io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig.PropertiesEntry] {
    implicit def messageCompanion: scalapb.GeneratedMessageCompanion[io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig.PropertiesEntry] = this
    def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig.PropertiesEntry = {
      var __key: _root_.scala.Predef.String = ""
      var __value: _root_.scala.Predef.String = ""
      var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
      var _done__ = false
      while (!_done__) {
        val _tag__ = _input__.readTag()
        _tag__ match {
          case 0 => _done__ = true
          case 10 =>
            __key = _input__.readStringRequireUtf8()
          case 18 =>
            __value = _input__.readStringRequireUtf8()
          case tag =>
            if (_unknownFields__ == null) {
              _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
            }
            _unknownFields__.parseField(tag, _input__)
        }
      }
      io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig.PropertiesEntry(
          key = __key,
          value = __value,
          unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
      )
    }
    implicit def messageReads: _root_.scalapb.descriptors.Reads[io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig.PropertiesEntry] = _root_.scalapb.descriptors.Reads{
      case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
        _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
        io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig.PropertiesEntry(
          key = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
          value = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Predef.String]).getOrElse("")
        )
      case _ => throw new RuntimeException("Expected PMessage")
    }
    def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig.javaDescriptor.getNestedTypes().get(0)
    def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig.scalaDescriptor.nestedMessages(0)
    def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = throw new MatchError(__number)
    lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
    def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
    lazy val defaultInstance = io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig.PropertiesEntry(
      key = "",
      value = ""
    )
    implicit class PropertiesEntryLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig.PropertiesEntry]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig.PropertiesEntry](_l) {
      def key: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.key)((c_, f_) => c_.copy(key = f_))
      def value: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.value)((c_, f_) => c_.copy(value = f_))
    }
    final val KEY_FIELD_NUMBER = 1
    final val VALUE_FIELD_NUMBER = 2
    @transient
    implicit val keyValueMapper: _root_.scalapb.TypeMapper[io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig.PropertiesEntry, (_root_.scala.Predef.String, _root_.scala.Predef.String)] =
      _root_.scalapb.TypeMapper[io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig.PropertiesEntry, (_root_.scala.Predef.String, _root_.scala.Predef.String)](__m => (__m.key, __m.value))(__p => io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig.PropertiesEntry(__p._1, __p._2))
    def of(
      key: _root_.scala.Predef.String,
      value: _root_.scala.Predef.String
    ): _root_.io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig.PropertiesEntry = _root_.io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig.PropertiesEntry(
      key,
      value
    )
    // @@protoc_insertion_point(GeneratedMessageCompanion[ustrp.integration.StorageConfig.PropertiesEntry])
  }
  
  implicit class StorageConfigLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig](_l) {
    def configId: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.configId)((c_, f_) => c_.copy(configId = f_))
    def pipelineId: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.pipelineId)((c_, f_) => c_.copy(pipelineId = f_))
    def tenantId: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.tenantId)((c_, f_) => c_.copy(tenantId = f_))
    def targetDatabase: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.targetDatabase)((c_, f_) => c_.copy(targetDatabase = f_))
    def targetSchema: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.targetSchema)((c_, f_) => c_.copy(targetSchema = f_))
    def targetTable: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.targetTable)((c_, f_) => c_.copy(targetTable = f_))
    def format: _root_.scalapb.lenses.Lens[UpperPB, io.gbmm.udps.integration.ustrp.stream_integration.StorageFormat] = field(_.format)((c_, f_) => c_.copy(format = f_))
    def compression: _root_.scalapb.lenses.Lens[UpperPB, io.gbmm.udps.integration.ustrp.stream_integration.CompressionCodec] = field(_.compression)((c_, f_) => c_.copy(compression = f_))
    def partitioning: _root_.scalapb.lenses.Lens[UpperPB, io.gbmm.udps.integration.ustrp.stream_integration.PartitionConfig] = field(_.getPartitioning)((c_, f_) => c_.copy(partitioning = _root_.scala.Option(f_)))
    def optionalPartitioning: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[io.gbmm.udps.integration.ustrp.stream_integration.PartitionConfig]] = field(_.partitioning)((c_, f_) => c_.copy(partitioning = f_))
    def compaction: _root_.scalapb.lenses.Lens[UpperPB, io.gbmm.udps.integration.ustrp.stream_integration.CompactionConfig] = field(_.getCompaction)((c_, f_) => c_.copy(compaction = _root_.scala.Option(f_)))
    def optionalCompaction: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[io.gbmm.udps.integration.ustrp.stream_integration.CompactionConfig]] = field(_.compaction)((c_, f_) => c_.copy(compaction = f_))
    def retention: _root_.scalapb.lenses.Lens[UpperPB, io.gbmm.udps.integration.ustrp.stream_integration.RetentionPolicy] = field(_.getRetention)((c_, f_) => c_.copy(retention = _root_.scala.Option(f_)))
    def optionalRetention: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[io.gbmm.udps.integration.ustrp.stream_integration.RetentionPolicy]] = field(_.retention)((c_, f_) => c_.copy(retention = f_))
    def tier: _root_.scalapb.lenses.Lens[UpperPB, io.gbmm.udps.integration.ustrp.stream_integration.StorageTier] = field(_.tier)((c_, f_) => c_.copy(tier = f_))
    def flushIntervalSeconds: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.flushIntervalSeconds)((c_, f_) => c_.copy(flushIntervalSeconds = f_))
    def maxBufferBytes: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.maxBufferBytes)((c_, f_) => c_.copy(maxBufferBytes = f_))
    def maxBufferRecords: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.maxBufferRecords)((c_, f_) => c_.copy(maxBufferRecords = f_))
    def schemaId: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.schemaId)((c_, f_) => c_.copy(schemaId = f_))
    def properties: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.collection.immutable.Map[_root_.scala.Predef.String, _root_.scala.Predef.String]] = field(_.properties)((c_, f_) => c_.copy(properties = f_))
    def createdAt: _root_.scalapb.lenses.Lens[UpperPB, com.google.protobuf.timestamp.Timestamp] = field(_.getCreatedAt)((c_, f_) => c_.copy(createdAt = _root_.scala.Option(f_)))
    def optionalCreatedAt: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[com.google.protobuf.timestamp.Timestamp]] = field(_.createdAt)((c_, f_) => c_.copy(createdAt = f_))
    def updatedAt: _root_.scalapb.lenses.Lens[UpperPB, com.google.protobuf.timestamp.Timestamp] = field(_.getUpdatedAt)((c_, f_) => c_.copy(updatedAt = _root_.scala.Option(f_)))
    def optionalUpdatedAt: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[com.google.protobuf.timestamp.Timestamp]] = field(_.updatedAt)((c_, f_) => c_.copy(updatedAt = f_))
  }
  final val CONFIG_ID_FIELD_NUMBER = 1
  final val PIPELINE_ID_FIELD_NUMBER = 2
  final val TENANT_ID_FIELD_NUMBER = 3
  final val TARGET_DATABASE_FIELD_NUMBER = 4
  final val TARGET_SCHEMA_FIELD_NUMBER = 5
  final val TARGET_TABLE_FIELD_NUMBER = 6
  final val FORMAT_FIELD_NUMBER = 7
  final val COMPRESSION_FIELD_NUMBER = 8
  final val PARTITIONING_FIELD_NUMBER = 9
  final val COMPACTION_FIELD_NUMBER = 10
  final val RETENTION_FIELD_NUMBER = 11
  final val TIER_FIELD_NUMBER = 12
  final val FLUSH_INTERVAL_SECONDS_FIELD_NUMBER = 13
  final val MAX_BUFFER_BYTES_FIELD_NUMBER = 14
  final val MAX_BUFFER_RECORDS_FIELD_NUMBER = 15
  final val SCHEMA_ID_FIELD_NUMBER = 16
  final val PROPERTIES_FIELD_NUMBER = 17
  final val CREATED_AT_FIELD_NUMBER = 18
  final val UPDATED_AT_FIELD_NUMBER = 19
  @transient
  private[stream_integration] val _typemapper_properties: _root_.scalapb.TypeMapper[io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig.PropertiesEntry, (_root_.scala.Predef.String, _root_.scala.Predef.String)] = implicitly[_root_.scalapb.TypeMapper[io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig.PropertiesEntry, (_root_.scala.Predef.String, _root_.scala.Predef.String)]]
  def of(
    configId: _root_.scala.Predef.String,
    pipelineId: _root_.scala.Predef.String,
    tenantId: _root_.scala.Predef.String,
    targetDatabase: _root_.scala.Predef.String,
    targetSchema: _root_.scala.Predef.String,
    targetTable: _root_.scala.Predef.String,
    format: io.gbmm.udps.integration.ustrp.stream_integration.StorageFormat,
    compression: io.gbmm.udps.integration.ustrp.stream_integration.CompressionCodec,
    partitioning: _root_.scala.Option[io.gbmm.udps.integration.ustrp.stream_integration.PartitionConfig],
    compaction: _root_.scala.Option[io.gbmm.udps.integration.ustrp.stream_integration.CompactionConfig],
    retention: _root_.scala.Option[io.gbmm.udps.integration.ustrp.stream_integration.RetentionPolicy],
    tier: io.gbmm.udps.integration.ustrp.stream_integration.StorageTier,
    flushIntervalSeconds: _root_.scala.Long,
    maxBufferBytes: _root_.scala.Long,
    maxBufferRecords: _root_.scala.Long,
    schemaId: _root_.scala.Predef.String,
    properties: _root_.scala.collection.immutable.Map[_root_.scala.Predef.String, _root_.scala.Predef.String],
    createdAt: _root_.scala.Option[com.google.protobuf.timestamp.Timestamp],
    updatedAt: _root_.scala.Option[com.google.protobuf.timestamp.Timestamp]
  ): _root_.io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig = _root_.io.gbmm.udps.integration.ustrp.stream_integration.StorageConfig(
    configId,
    pipelineId,
    tenantId,
    targetDatabase,
    targetSchema,
    targetTable,
    format,
    compression,
    partitioning,
    compaction,
    retention,
    tier,
    flushIntervalSeconds,
    maxBufferBytes,
    maxBufferRecords,
    schemaId,
    properties,
    createdAt,
    updatedAt
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[ustrp.integration.StorageConfig])
}
